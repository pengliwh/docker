#!/bin/bash -e
#  _
# | |_ ___ _ __ ___  _ __   ___     ___  _ __  
# | __/ _ \ '_ ` _ \| '_ \ / _ \   / _ \| '_ \ 
# | ||  __/ | | | | | |_) | (_) | | (_) | | | |
#  \__\___|_| |_| |_| .__/ \___/   \___/|_| |_|
#                   |_|                        
#                       _      ____  
#  ___ _ __   __ _ _ __| | __ |___ \ 
# / __| '_ \ / _` | '__| |/ /   __) |
# \__ \ |_) | (_| | |  |   <   / __/ 
# |___/ .__/ \__,_|_|  |_|\_\ |_____|
#     |_|  

umask 022 # directory permissions are 755 and file permissions are 644.

cat << "EOF"
  _
 | |_ ___ _ __ ___  _ __   ___     ___  _ __  
 | __/ _ \ '_ ` _ \| '_ \ / _ \   / _ \| '_ \ 
 | ||  __/ | | | | | |_) | (_) | | (_) | | | |
  \__\___|_| |_| |_| .__/ \___/   \___/|_| |_|
                   |_|                        
                      _      ____  
 ___ _ __   __ _ _ __| | __ |___ \ 
/ __| '_ \ / _` | '__| |/ /   __) |
\__ \ |_) | (_| | |  |   <   / __/ 
|___/ .__/ \__,_|_|  |_|\_\ |_____|
    |_|  
EOF

# if tempo initialize
if [[ ! -f init.done ]]; then
    echo "Tempo is not ready, run ./bin/init-tempo.sh first"
    exit 9 
fi

# if load .env-tempo
if [[ -f .env-tempo ]]; then
	. .env-tempo
	# spark2.x require java1.8 or later
	export JAVA_HOME=/opt/jdk1.8.0_171
	export PATH=${JAVA_HOME}/bin:${PATH}
fi

# if find spark-submit
if [[ ! -x $(which spark-submit) ]]; then
	echo "Can't locate spark-submit in your \$PATH."
	exit 9
fi

function usage {
	echo "$0 <etl.id>"
	exit 1	
}

if [[ $# -eq 1 ]]; then
	etl_id=$1
	dry_run_flg=0
elif [[ $# -eq 2 ]]; then
	etl_id=$1
	if [[ $2 == "--dry-run" ]]; then
		dry_run_flg=1
	else
		usage	
	fi
else
	usage
fi

project_id=$(echo $etl_id|cut -d"." -f1)
feed_id=$(echo $etl_id|cut -d"." -f2)

if [[ -f dat/$project_id/$feed_id.timestamp ]]; then
	etl_timestamp=$(cat dat/$project_id/$feed_id.timestamp)
else
	date +'%Y-%m-%d' > dat/$project_id/$feed_id.timestamp
	etl_timestamp=$(cat dat/$project_id/$feed_id.timestamp)
fi

if [[ -f cfg/$project_id/$feed_id.cfg ]]; then
        cfg_file=cfg/$project_id/$feed_id.cfg
else
        echo "ERROR: can't find cfg file ${cfg_file}"
        exit 2
fi

if [[ -f sql/$project_id/$feed_id.del.sql ]] && [[ -s sql/$project_id/$feed_id.inc.sql ]]; then 
        inc_sql=sql/$project_id/$feed_id.inc.sql
        del_sql=sql/$project_id/$feed_id.del.sql
else
        echo "ERROR: required del.sql & non-empty inc.sql"
        exit 2
fi

if [[ ! -f dat/$project_id/$feed_id.batch ]]; then
	echo "1" > dat/$project_id/$feed_id.batch
	etl_batch=1
else
	etl_batch=$(cat dat/$project_id/$feed_id.batch)
fi

log_file="log/$project_id/$feed_id.$etl_batch."$(date +'%Y%m%d_%H%M%S').log
dbc_list=$(grep -v '^#' $cfg_file|grep '.*=.*dbc$'|awk -F '=' '{print "dbc/"$2}'|sort|uniq|tr '\n' ',')

if [[ -z ${SPARK_RESOURCE_OPT+x} ]]; then
	SPARK_RESOURCE_OPT="--num-executors 4 --executor-memory 10g --executor-cores 2 --driver-memory 5g"
else
	echo "WARN: SPARK_RESOURCE_OPT is set as '${SPARK_RESOURCE_OPT}'"
	# --num-executors 4 --queue cscs_dw_apollo --executor-memory 20g --executor-cores 4 --driver-memory 5g
fi

# submit sparkSQL driver programe
spark2-submit --class tempo.spark2.DriverMain \
--master yarn --deploy-mode client \
$SPARK_RESOURCE_OPT \
--jars lib/ojdbc6.jar,lib/mysql-connector-java-5.1.44-bin.jar,lib/tempo-udf.jar,lib/tempo-common.jar,lib/hive-serde/*.jar \
--conf spark.driver.host=10.100.49.110 \
--conf spark.sql.parquet.writeLegacyFormat=true \
--conf spark.network.timeout=300000 \
--files ${dbc_list}$cfg_file,$del_sql,$inc_sql \
lib/tempo-spark2.jar $etl_id $cfg_file $del_sql $inc_sql "$etl_timestamp" $dry_run_flg 2>&1 | tee $log_file

# Error handle
# for yarn cluster mode
if [[ ! $(grep 'DriverMainError' $log_file) ]]; then
	etl_batch=$((etl_batch+1))
	echo $etl_batch > dat/$project_id/$feed_id.batch
else
	exit 4 
fi
